{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8GJbpoUmYdT"
   },
   "source": [
    "# Saliency Maps with HuggingFace and TextualHeatmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tur-G6LngqL"
   },
   "source": [
    "As described in [Andreas Madsen's distill paper](https://distill.pub/2019/memorization-in-rnns/), the saliency map is computed by measuring the gradient magnitude of the output w.r.t. the input.\n",
    "\n",
    "$$\n",
    "\\mathrm{connectivity}(t, \\tilde{t}) = \\left|\\left| \\frac{\\partial y^{\\tilde{t}}_{k}}{\\partial x^t} \\right|\\right|_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IMyHY55SC24O"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from textualheatmap import TextualHeatmap\n",
    "from datasets import Dataset\n",
    "\n",
    "from datagen.dataset import SemCorDataSet\n",
    "from modelling.model import SynsetClassificationModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_key(idx, sense_keys):\n",
    "    keys = sense_keys.loc[sense_keys['sense-key-idx'] == idx]['sense-key1'].values\n",
    "    if keys.size == 0:\n",
    "        # temporary till labels of test are fixed\n",
    "        return \"NONE\"\n",
    "    return keys[0]\n",
    "\n",
    "def compute_textual_saliency(model, tokenizer, text, sense_keys):\n",
    "    token_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "    embeddings = model.mlmodel.embeddings.word_embeddings\n",
    "    vocab_size = embeddings.num_embeddings\n",
    "\n",
    "    heatmap_data = []\n",
    "\n",
    "    for masked_token_index in range(len(token_ids)):\n",
    "        # print(f'processing token {masked_token_index + 1} / {len(token_ids)}')\n",
    "\n",
    "        if masked_token_index == 0:\n",
    "            heatmap_data.append({\n",
    "                'token': '[CLR]',\n",
    "                'meta': ['', '', ''],\n",
    "                'heat': [1] + [0] * (len(token_ids) - 1)\n",
    "            })\n",
    "            heatmap_data.append({\n",
    "                'token': ' ',\n",
    "                'format': True\n",
    "            })\n",
    "        elif masked_token_index == len(token_ids) - 1:\n",
    "            heatmap_data.append({\n",
    "                'token': ' ',\n",
    "                'format': True\n",
    "            })\n",
    "            heatmap_data.append({\n",
    "                'token': '[SEP]',\n",
    "                'meta': ['', '', ''],\n",
    "                'heat': [0] * (len(token_ids) - 1) + [1]\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            # Get the actual token\n",
    "            target_token = tokenizer.convert_ids_to_tokens(\n",
    "                token_ids[masked_token_index], skip_special_tokens=True)\n",
    "                            \n",
    "            if target_token[0] == 'Ä ':\n",
    "                target_token = target_token[1:]\n",
    "                heatmap_data.append({\n",
    "                    'token': ' ',\n",
    "                    'format': True\n",
    "                })\n",
    "\n",
    "            # integers are not differentable, so use a one-hot encoding\n",
    "            # of the intput\n",
    "            token_ids_tensor = torch.tensor(token_ids, dtype=torch.int64)\n",
    "            token_ids_tensor[masked_token_index] = tokenizer.mask_token_id\n",
    "            token_ids_tensor_one_hot = F.one_hot(token_ids_tensor, vocab_size).float()\n",
    "            token_ids_tensor_one_hot.requires_grad = True\n",
    "\n",
    "            # To select, the correct output witch is what the importance\n",
    "            # measure targets, create a masking tensor. tf.gather_nd could also\n",
    "            # be used, but this is easier.\n",
    "            output_mask = torch.zeros((1, len(token_ids), model.num_classes))\n",
    "\n",
    "            # Compute gradient of the logits of the correct target, w.r.t. the\n",
    "            # input\n",
    "            inputs_embeds = torch.matmul(token_ids_tensor_one_hot, embeddings.weight)\n",
    "            dummy = torch.full_like(token_ids_tensor, -100)\n",
    "            output = model(**{\"inputs_embeds\": inputs_embeds.unsqueeze(dim=0), \"labels\": dummy, \"sense-labels\": dummy})\n",
    "            logits = output.logits\n",
    "\n",
    "            # Get the top-3 predictions\n",
    "            (_, top_3_indices) = torch.topk(logits[masked_token_index, :], 3)\n",
    "\n",
    "            # !!! contrary the original impl. we do not look at grads for gold labels, instead for top pred !!!\n",
    "            output_mask[0, masked_token_index, top_3_indices[0]] = 1\n",
    "            predict_mask_correct_token = torch.sum(logits * output_mask)\n",
    "            predict_mask_correct_token.backward()\n",
    "\n",
    "            # compute the connectivity\n",
    "            connectivity_non_normalized = torch.norm(token_ids_tensor_one_hot.grad, dim=1)\n",
    "            connectivity_tensor = (\n",
    "                connectivity_non_normalized /\n",
    "                torch.max(connectivity_non_normalized)\n",
    "            )\n",
    "\n",
    "            connectivity = connectivity_tensor.numpy().tolist()\n",
    "            assert(len(connectivity) == len(token_ids))\n",
    "            model.zero_grad()\n",
    "            pred_keys = [get_key(idx, sense_keys) for idx in top_3_indices.tolist()]\n",
    "\n",
    "            heatmap_data.append({\n",
    "                'token': target_token,\n",
    "                'meta': pred_keys,\n",
    "                'heat': connectivity\n",
    "            })\n",
    "\n",
    "    return heatmap_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CF-V7r0o-g7"
   },
   "source": [
    "With this implementation, it is now possible to compare different BERT-like models. In theory any model can be compared, as long as the tokenization is the same. In this case the BERT and DistillBERT models are very similar, which is what we would expect and want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "KzS9z-lVeBTl",
    "outputId": "74ec05a4-cec7-407a-8729-8fcaaa2c1d7c"
   },
   "outputs": [],
   "source": [
    "def construct_model_name(hf_model: str):\n",
    "    if \"bert-wwm\" in hf_model:\n",
    "        model_name = \"bert-large-uncased-whole-word-masking\"\n",
    "    elif \"roberta\" in hf_model:\n",
    "        model_name = \"roberta-base\"\n",
    "    else:\n",
    "        assert \"deberta\" in hf_model\n",
    "        model_name = \"microsoft/deberta-base\"\n",
    "    return model_name\n",
    "\n",
    "def load_model(model_path: str):\n",
    "    base_model_name = construct_model_name(model_path)\n",
    "    config = AutoConfig.from_pretrained(model_path, local_files_only=True)\n",
    "    cl_model = SynsetClassificationModel.from_pretrained(\n",
    "        model_path,\n",
    "        config=config,\n",
    "        local_files_only=True,\n",
    "        model_name=base_model_name,\n",
    "        num_classes=2584,\n",
    "        freeze_lm=False,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "    return cl_model, tokenizer\n",
    "\n",
    "def print_saliency(text, model, tokenizer, model_display_name):\n",
    "    data_path = Path(\"./dataset/roberta+semeval2013.pickle\")\n",
    "    ds = SemCorDataSet.unpickle(data_path.with_suffix(\".pickle\"))\n",
    "    keys = ds.all_sense_keys\n",
    "\n",
    "    heatmap = TextualHeatmap(facet_titles = [model_display_name], show_meta=True)\n",
    "    heatmap.set_data([\n",
    "        compute_textual_saliency(model, tokenizer, text, keys),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta Probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "KzS9z-lVeBTl",
    "outputId": "74ec05a4-cec7-407a-8729-8fcaaa2c1d7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "roberta_model, roberta_tokenizer = load_model(\"out/checkpoints/roberta-probing+semcor/checkpoint-185900\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.textual-heatmap .facet {\n",
       "  display: grid;\n",
       "  grid-template-columns: 1fr 60px;\n",
       "  grid-template-rows: 40px auto;\n",
       "  grid-template-areas:\n",
       "    \"meta-content .\"\n",
       "    \"token-content facet-title\";\n",
       "  margin-bottom: 0.5em;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet.hide-meta-content {\n",
       "  grid-template-rows: auto;\n",
       "  grid-template-areas:\n",
       "    \"token-content facet-title\";\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .token-content {\n",
       "  grid-area: token-content;\n",
       "\n",
       "  font-family: monospace;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  background: #365d8d;\n",
       "  color: white;\n",
       "  line-height: 1.4em;\n",
       "  border-radius: 0 0 0 5px;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet.hide-meta-content .token-content {\n",
       "    border-radius: 5px 0 0 5px;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .token-content span {\n",
       "  border-bottom: 0.2em solid transparent;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .token-content span.selected {\n",
       "  border-bottom-color: white;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content {\n",
       "  grid-area: meta-content;\n",
       "  display: grid;\n",
       "  grid-template-columns: repeat(auto-fit, minmax(0px, 1fr));\n",
       "  grid-column-gap: 2px;\n",
       "  align-items: center;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet.hide-meta-content .meta-content {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content .meta-content-item {\n",
       "  display: flex;\n",
       "  justify-content: center;\n",
       "  align-items: center;\n",
       "  padding: 0 5px;\n",
       "  height: 39px;\n",
       "  background: #F3F3F3;\n",
       "  border: 1px solid #E0E0E0;\n",
       "  color: black;\n",
       "  border-bottom: none;\n",
       "  text-overflow: ellipsis;\n",
       "  overflow: hidden;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content .meta-content-item:first-of-type {\n",
       "    border-radius: 5px 0 0 0;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content .meta-content-item:last-of-type {\n",
       "    border-radius: 0 5px 0 0;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .meta-content .meta-content-item:first-of-type:last-of-type {\n",
       "    border-radius: 5px 5px 0 0;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .facet-title {\n",
       "  grid-area: facet-title;\n",
       "\n",
       "  display: flex;\n",
       "  max-width: 60px;\n",
       "  background: #EEEEEE;\n",
       "  justify-content: center;\n",
       "  color: #555555;\n",
       "  border-radius: 0 5px 5px 0;\n",
       "  border: 1px solid #E0E0E0;\n",
       "  border-left: none;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet .facet-title span {\n",
       "  align-self: center;\n",
       "  display: inline-block;\n",
       "  transform-origin: center center;\n",
       "  line-height: 1em;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".textual-heatmap .facet.rotate-facet-title .facet-title span {\n",
       "  transform: translate(0, 0) rotate(90deg);\n",
       "}</style><script>;(function () {\n",
       "    'use strict';\n",
       "\n",
       "    function viridisSubset(ratio) {\n",
       "        const colormap = [\n",
       "            '#365d8d', '#355e8d', '#355f8d', '#34608d', '#34618d',\n",
       "            '#33628d', '#33638d', '#32648e', '#32658e', '#31668e',\n",
       "            '#31678e', '#31688e', '#30698e', '#306a8e', '#2f6b8e',\n",
       "            '#2f6c8e', '#2e6d8e', '#2e6e8e', '#2e6f8e', '#2d708e',\n",
       "            '#2d718e', '#2c718e', '#2c728e', '#2c738e', '#2b748e',\n",
       "            '#2b758e', '#2a768e', '#2a778e', '#2a788e', '#29798e',\n",
       "            '#297a8e', '#297b8e', '#287c8e', '#287d8e', '#277e8e',\n",
       "            '#277f8e', '#27808e', '#26818e', '#26828e', '#26828e',\n",
       "            '#25838e', '#25848e', '#25858e', '#24868e', '#24878e',\n",
       "            '#23888e', '#23898e', '#238a8d', '#228b8d', '#228c8d',\n",
       "            '#228d8d', '#218e8d', '#218f8d', '#21908d', '#21918c',\n",
       "            '#20928c', '#20928c', '#20938c', '#1f948c', '#1f958b',\n",
       "            '#1f968b', '#1f978b', '#1f988b', '#1f998a', '#1f9a8a',\n",
       "            '#1e9b8a', '#1e9c89', '#1e9d89', '#1f9e89', '#1f9f88',\n",
       "            '#1fa088', '#1fa188', '#1fa187', '#1fa287', '#20a386',\n",
       "            '#20a486', '#21a585', '#21a685', '#22a785', '#22a884',\n",
       "            '#23a983', '#24aa83', '#25ab82', '#25ac82', '#26ad81',\n",
       "            '#27ad81', '#28ae80', '#29af7f', '#2ab07f', '#2cb17e',\n",
       "            '#2db27d', '#2eb37c', '#2fb47c', '#31b57b', '#32b67a',\n",
       "            '#34b679', '#35b779'\n",
       "        ];\n",
       "        const n = colormap.length - 1;\n",
       "        return colormap[Math.max(0, Math.min(n, Math.floor(ratio * n)))];\n",
       "    }\n",
       "\n",
       "    class TextualHeatmap {\n",
       "        constructor(settings) {\n",
       "            this.container = document.getElementById(settings.id);\n",
       "            this.container.style.width = settings.width + 'px';\n",
       "            this.facets = settings.facetTitles\n",
       "                .map((facetName) => new TextualHeatmapFacet(settings, this.container, facetName));\n",
       "\n",
       "            for (let i = 0; i < this.facets.length; i++) {\n",
       "                this.facets[i].onmouseover = this.highlight.bind(this);\n",
       "            }\n",
       "        }\n",
       "\n",
       "        setData(data) {\n",
       "            for (let i = 0; i < this.facets.length; i++) {\n",
       "                this.facets[i].setData(data[i]);\n",
       "            }\n",
       "        }\n",
       "\n",
       "        highlight(index) {\n",
       "            for (let i = 0; i < this.facets.length; i++) {\n",
       "                this.facets[i].highlight(index);\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "\n",
       "    class TextualHeatmapFacet {\n",
       "        constructor(settings, root, facetName) {\n",
       "            this.settings = settings;\n",
       "            this.highlightIndex = null;\n",
       "            this.nonFormatData = [];\n",
       "            this.heatIndexToNodeElement = [];\n",
       "            this.root = root;\n",
       "            this.onmouseover = null;\n",
       "\n",
       "            this.facet = document.createElement('div');\n",
       "            this.facet.classList.add('facet');\n",
       "            this.facet.classList.toggle('hide-meta-content', !settings.showMeta);\n",
       "            this.facet.classList.toggle('rotate-facet-title', settings.rotateFacetTitles);\n",
       "            this.root.appendChild(this.facet);\n",
       "\n",
       "            this.meta = document.createElement('div');\n",
       "            this.meta.classList.add('meta-content');\n",
       "            this.facet.appendChild(this.meta);\n",
       "\n",
       "            const item = document.createElement('div');\n",
       "            item.classList.add('meta-content-item');\n",
       "            this.meta.appendChild(item);\n",
       "\n",
       "            this.content = document.createElement('div');\n",
       "            this.content.classList.add('token-content');\n",
       "            this.facet.appendChild(this.content);\n",
       "\n",
       "            this.title = document.createElement('div');\n",
       "            this.title.classList.add('facet-title');\n",
       "            const titleSpan = document.createElement('span');\n",
       "            titleSpan.appendChild(document.createTextNode(facetName));\n",
       "            this.title.appendChild(titleSpan);\n",
       "            this.facet.appendChild(this.title);\n",
       "        }\n",
       "\n",
       "        setData(data) {\n",
       "            this.nonFormatData = [];\n",
       "            this.heatIndexToNodeElement = []\n",
       "\n",
       "            while (this.content.childNodes.length > 0) {\n",
       "                this.content.removeChild(this.content.firstChild);\n",
       "            }\n",
       "\n",
       "            for (let i = 0; i < data.length; i++) {\n",
       "                const tokenNode = document.createElement('span');\n",
       "                const heatIndex = this.heatIndexToNodeElement.length;\n",
       "                tokenNode.appendChild(document.createTextNode(data[i].token));\n",
       "                if (this.settings.interactive && !data[i].format) {\n",
       "                    tokenNode.addEventListener('mouseover', () => this.onmouseover(heatIndex), false);\n",
       "                    this.heatIndexToNodeElement.push(tokenNode)\n",
       "                    this.nonFormatData.push(data[i])\n",
       "                }\n",
       "                this.content.appendChild(tokenNode);\n",
       "            }\n",
       "\n",
       "            if (this.highlightIndex !== null) {\n",
       "                this.highlight(this.highlightIndex);\n",
       "            }\n",
       "        }\n",
       "\n",
       "        highlight(index) {\n",
       "            this.highlightIndex = index;\n",
       "\n",
       "            for (let i = 0; i < this.heatIndexToNodeElement.length; i++) {\n",
       "                this.heatIndexToNodeElement[i].style.backgroundColor = viridisSubset(this.nonFormatData[index].heat[i]);\n",
       "                this.heatIndexToNodeElement[i].classList.toggle('selected', i === index);\n",
       "            }\n",
       "\n",
       "            if (this.settings.showMeta) {\n",
       "                while (this.meta.childNodes.length > 0) {\n",
       "                    this.meta.removeChild(this.meta.firstChild);\n",
       "                }\n",
       "\n",
       "                for (let i = 0; i < this.nonFormatData[index].meta.length; i++) {\n",
       "                    const item = document.createElement('div');\n",
       "                    item.classList.add('meta-content-item');\n",
       "                    item.appendChild(document.createTextNode(this.nonFormatData[index].meta[i]));\n",
       "                    this.meta.appendChild(item);\n",
       "                }\n",
       "\n",
       "                if (this.nonFormatData[index].meta.length === 0) {\n",
       "                    const item = document.createElement('div');\n",
       "                    item.classList.add('meta-content-item');\n",
       "                    this.meta.appendChild(item);\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "\n",
       "    window.setupTextualHeatmap = function (settings) {\n",
       "        document.getElementById(settings.id).instance = new TextualHeatmap(settings);\n",
       "    };\n",
       "\n",
       "    window.setDataTextualHeatmap = function (settings, data) {\n",
       "        document.getElementById(settings.id).instance.setData(data);\n",
       "    };\n",
       "\n",
       "    window.highlightTextualHeatmap = function (settings, index) {\n",
       "        document.getElementById(settings.id).instance.highlight(index);\n",
       "    };\n",
       "})();</script><div id=\"4e4c5770-3bab-4945-a260-9439ea861354\" class=\"textual-heatmap\"></div><script>  window.setupTextualHeatmap({\"id\": \"4e4c5770-3bab-4945-a260-9439ea861354\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Roberta-Probing\"], \"rotateFacetTitles\": false, \"interactive\": true});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>  window.setDataTextualHeatmap({\"id\": \"4e4c5770-3bab-4945-a260-9439ea861354\", \"width\": 600, \"showMeta\": true, \"facetTitles\": [\"Roberta-Probing\"], \"rotateFacetTitles\": false, \"interactive\": true}, [[{\"token\": \"[CLR]\", \"meta\": [\"\", \"\", \"\"], \"heat\": [1, 0, 0, 0, 0, 0, 0]}, {\"token\": \" \", \"format\": true}, {\"token\": \"This\", \"meta\": [\"plan%1:09:00::\", \"indication%1:10:00::\", \"climate_change%1:22:00::\"], \"heat\": [0.2502235174179077, 0.5740206241607666, 1.0, 0.6474472284317017, 0.5880831480026245, 0.38012802600860596, 0.27899956703186035]}, {\"token\": \" \", \"format\": true}, {\"token\": \"thing\", \"meta\": [\"NONE\", \"plan%1:09:00::\", \"hymn%1:10:00::\"], \"heat\": [0.27725905179977417, 0.682034969329834, 0.6122264266014099, 0.7947134375572205, 1.0, 0.5255717039108276, 0.36554139852523804]}, {\"token\": \" \", \"format\": true}, {\"token\": \"finally\", \"meta\": [\"plan%1:09:00::\", \"leader%1:18:00::\", \"region%1:15:01::\"], \"heat\": [0.2887030243873596, 0.7658483982086182, 1.0, 0.5995534658432007, 0.9410401582717896, 0.7211493849754333, 0.42860549688339233]}, {\"token\": \" \", \"format\": true}, {\"token\": \"works\", \"meta\": [\"plan%1:09:00::\", \"constancy%1:07:00::\", \"oil_company%1:14:00::\"], \"heat\": [0.2773040533065796, 0.6323971748352051, 1.0, 0.8095434308052063, 0.40639281272888184, 0.40956205129623413, 0.28185179829597473]}, {\"token\": \"!\", \"meta\": [\"organization%1:14:00::\", \"NONE\", \"NONE\"], \"heat\": [0.2759900689125061, 0.6225048899650574, 0.7618217468261719, 1.0, 0.7817369699478149, 0.6462106108665466, 0.47735196352005005]}, {\"token\": \" \", \"format\": true}, {\"token\": \"[SEP]\", \"meta\": [\"\", \"\", \"\"], \"heat\": [0, 0, 0, 0, 0, 0, 1]}]]);</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "void(0);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_saliency(\"This thing finally works!\", roberta_model, roberta_tokenizer, \"Roberta-Probing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "TextualHeatmap.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}