{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "30l9ZyTjxJjf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import datagen\n",
    "from datagen.dataset import SemCorDataSet\n",
    "import datasets # prevent circular module import exception\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from modelling.collator import BetterDataCollatorForWholeWordMask\n",
    "from modelling.model import SynsetClassificationModel\n",
    "from modelling.trainer import BetterTrainer\n",
    "from lit_nlp.api import types as lit_types\n",
    "from lit_nlp.api.dataset import Dataset\n",
    "from lit_nlp.api.model import Model\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(path: str):\n",
    "    ds = datagen.SemCorDataSet.unpickle(Path(path).with_suffix(\".pickle\"))\n",
    "    hf_ds = datasets.Dataset.load_from_disk(Path(path).with_suffix(\".hf\"))\n",
    "    \n",
    "    hf_ds = hf_ds.add_column(\"sense-labels\", hf_ds[\"labels\"])\n",
    "    relevant_columns = [\n",
    "        column\n",
    "        for column in hf_ds.column_names\n",
    "        if column not in ds.sentence_level.columns\n",
    "    ]\n",
    "    relevant_columns.extend([\"sense-labels\"])\n",
    "    hf_ds.set_format(type=\"torch\", columns=relevant_columns)\n",
    "    \n",
    "    return ds, hf_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path: str):\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        print(f\"CUDA found; running on {device}\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(f\"CUDA not found; running on {device}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(path, local_files_only=True)\n",
    "    \n",
    "    model = SynsetClassificationModel.from_pretrained(\n",
    "        path,\n",
    "        config=AutoConfig.from_pretrained(path, local_files_only=True),\n",
    "        local_files_only=True,\n",
    "        model_name=path,\n",
    "        num_classes=2584,\n",
    "    ).to(device)\n",
    "    \n",
    "    trainer = BetterTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForLanguageModeling(tokenizer),\n",
    "        args=TrainingArguments(\n",
    "            output_dir='./saliency',\n",
    "            remove_unused_columns=False,\n",
    "            label_names=[\"labels\", \"sense-labels\"]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SemCorDataSet.unpickle(\"dataset/roberta+senseval2.pickle\")\n",
    "VOCAB = ds.all_sense_keys['sense-key1'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to https://pair-code.github.io/lit/setup/ for implementation details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIT_Dataset(Dataset):\n",
    "    def __init__(self, path: str, tokenizer):\n",
    "        ds, hf_ds = load_dataset(path)    \n",
    "        self._examples = [\n",
    "            {\n",
    "                \"sentence\": sentence,\n",
    "                'input_ids': row[\"input_ids\"].numpy(),\n",
    "                'attention_mask': row['attention_mask'].numpy(),\n",
    "                'labels': row['labels'].numpy(),\n",
    "                \"sense-labels\": row[\"sense-labels\"].numpy(),\n",
    "            }\n",
    "            for row, sentence in zip(hf_ds, ds.sentence_level[\"sentence\"])\n",
    "        ]\n",
    "        \n",
    "        #print(sentences[0], tok_sentences[0], sense_idxs[0])\n",
    "        #print(self._examples)\n",
    "\n",
    "    def spec(self):\n",
    "        return {\n",
    "            \"sentence\": lit_types.TextSegment(),\n",
    "            \"input_ids\": lit_types.Embeddings(),\n",
    "            'attention_mask': lit_types.Embeddings(),\n",
    "            'labels': lit_types.CategoryLabel(),\n",
    "            \"sense-labels\": lit_types.CategoryLabel(),\n",
    "        }\n",
    "\n",
    "\n",
    "class LIT_Model(Model):\n",
    "    def __init__(self, path: str, ds: SemCorDataSet):\n",
    "        self.trainer = load_model(path)\n",
    "        self.ds = ds\n",
    "\n",
    "    def input_spec(self):\n",
    "        return {\n",
    "            #\n",
    "            # \"input_ids\": lit_types.TextSegment(),\n",
    "            \"sense-labels\":  lit_types.CategoryLabel(),\n",
    "            'attention_mask': lit_types.Embeddings(),\n",
    "            'labels': lit_types.CategoryLabel()\n",
    "        }\n",
    "\n",
    "    def output_spec(self):\n",
    "        return {\n",
    "            \"probs\": lit_types.MulticlassPreds(vocab=VOCAB, parent='sense-labels', null_idx=-100),\n",
    "            # \"tokens\": lit_types.Tokens(parent=\"sentence\")\n",
    "        }\n",
    "\n",
    "    def predict_minibatch(self, inputs):\n",
    "        outputs = list()\n",
    "        for i in inputs:\n",
    "            copyi = i.copy()\n",
    "            _ = copyi.pop(\"sentence\")\n",
    "            \n",
    "            tensor_i = {k: torch.tensor(v).unsqueeze(dim=1) for k, v in copyi.items()}\n",
    "            #print(tensor_i)\n",
    "            \n",
    "            loss, logits, labels = self.trainer.prediction_step(\n",
    "                self.trainer.model, \n",
    "                tensor_i, \n",
    "                prediction_loss_only=False\n",
    "            )\n",
    "            \n",
    "            probas = torch.nn.functional.softmax(logits, dim=-1).squeeze().cpu().numpy()\n",
    "            \n",
    "            outputs.append({'probs': probas,\n",
    "                            'tokens': i[\"input_ids\"]})\n",
    "        #print(outputs)\n",
    "        return outputs\n",
    "#             #print(pred)\n",
    "            \n",
    "#             #print(pred)\n",
    "#             #print(logits)\n",
    "#             #print(label_ids)\n",
    "\n",
    "#             sense_labels = tensor_i[\"sense-labels\"][:]\n",
    "#             sense_labels[tensor_i[\"labels\"] == -100] = -100\n",
    "\n",
    "#             # Get IDs\n",
    "#             masks_idx = sense_labels != -100\n",
    "#             predictions = np.argmax(logits.cpu().numpy(), axis=-1)[masks_idx.flatten()]\n",
    "#             reference = sense_labels[masks_idx]\n",
    "            \n",
    "#             sense_keys = list()\n",
    "            \n",
    "#             sks = self.ds.all_sense_keys\n",
    "#             #print(sks.shape)\n",
    "            \n",
    "#             if len(reference):\n",
    "#                 for ref in reference.numpy():\n",
    "#                     # print(ref)\n",
    "#                     r = sks[sks[\"sense-key-idx\"] == ref]\n",
    "#                     if not r[\"sense-key1\"].shape[0]:\n",
    "#                         sense_keys.append(None)\n",
    "#                     else:\n",
    "#                         ref_sk = r[\"sense-key1\"].iloc[0]\n",
    "#                         sense_keys.append(ref_sk)\n",
    "#             else:\n",
    "#                 sense_keys.append(None)\n",
    "            \n",
    "#             #print(sense_keys)\n",
    "#             if any(s is not None for s in sense_keys):\n",
    "#                 outputs.append({\"prediction\": next(filter(None, sense_keys))})\n",
    "#             else:\n",
    "#                 outputs.append({\"prediction\": \"unknown\"})\n",
    "            \n",
    "#         # print(outputs)\n",
    "#         return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AWhbAZg57RpB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/added_tokens.json. We won't load it.\n",
      "loading file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/vocab.json\n",
      "loading file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/merges.txt\n",
      "loading file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/tokenizer.json\n",
      "loading file None\n",
      "loading file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/special_tokens_map.json\n",
      "loading file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/tokenizer_config.json\n",
      "loading configuration file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"./out/checkpoints/roberta-probing+semcor/checkpoint-185900\",\n",
      "  \"architectures\": [\n",
      "    \"SynsetClassificationModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/pytorch_model.bin\n",
      "loading configuration file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"./out/checkpoints/roberta-probing+semcor/checkpoint-185900\",\n",
      "  \"architectures\": [\n",
      "    \"SynsetClassificationModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file ./out/checkpoints/roberta-probing+semcor/checkpoint-185900/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA found; running on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./out/checkpoints/roberta-probing+semcor/checkpoint-185900 were not used when initializing RobertaModel: ['mlmodel.encoder.layer.11.attention.output.dense.bias', 'mlmodel.encoder.layer.2.attention.self.value.bias', 'mlmodel.embeddings.word_embeddings.weight', 'mlmodel.encoder.layer.0.attention.output.dense.bias', 'mlmodel.encoder.layer.6.attention.self.value.bias', 'mlmodel.pooler.dense.weight', 'mlmodel.encoder.layer.10.intermediate.dense.weight', 'mlmodel.encoder.layer.7.intermediate.dense.weight', 'mlmodel.encoder.layer.3.attention.self.value.weight', 'mlmodel.encoder.layer.0.output.dense.bias', 'mlmodel.encoder.layer.0.attention.output.dense.weight', 'classifier.1.weight', 'mlmodel.encoder.layer.10.output.dense.weight', 'mlmodel.encoder.layer.3.attention.self.key.bias', 'mlmodel.encoder.layer.7.output.dense.bias', 'mlmodel.encoder.layer.2.attention.output.LayerNorm.bias', 'mlmodel.pooler.dense.bias', 'mlmodel.encoder.layer.8.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.4.output.dense.weight', 'mlmodel.encoder.layer.9.attention.output.dense.weight', 'mlmodel.encoder.layer.11.attention.self.value.weight', 'mlmodel.embeddings.LayerNorm.bias', 'mlmodel.encoder.layer.0.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.2.intermediate.dense.bias', 'mlmodel.encoder.layer.2.output.dense.bias', 'mlmodel.encoder.layer.4.attention.self.value.weight', 'mlmodel.encoder.layer.9.attention.self.query.bias', 'mlmodel.encoder.layer.10.attention.self.key.bias', 'mlmodel.encoder.layer.11.output.dense.weight', 'mlmodel.encoder.layer.4.attention.output.dense.weight', 'mlmodel.encoder.layer.4.attention.self.query.bias', 'mlmodel.encoder.layer.7.attention.output.dense.weight', 'mlmodel.encoder.layer.7.output.dense.weight', 'mlmodel.encoder.layer.9.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.10.intermediate.dense.bias', 'mlmodel.encoder.layer.6.output.dense.bias', 'mlmodel.encoder.layer.10.output.LayerNorm.weight', 'mlmodel.encoder.layer.2.attention.self.query.weight', 'mlmodel.encoder.layer.2.attention.output.dense.weight', 'mlmodel.encoder.layer.10.attention.self.query.weight', 'mlmodel.encoder.layer.5.output.dense.weight', 'mlmodel.encoder.layer.6.intermediate.dense.bias', 'mlmodel.encoder.layer.4.output.dense.bias', 'mlmodel.encoder.layer.6.attention.self.query.weight', 'mlmodel.encoder.layer.9.attention.self.query.weight', 'mlmodel.encoder.layer.9.attention.self.key.bias', 'mlmodel.encoder.layer.0.attention.self.key.bias', 'mlmodel.encoder.layer.1.intermediate.dense.bias', 'classifier.1.bias', 'mlmodel.encoder.layer.11.output.LayerNorm.weight', 'mlmodel.encoder.layer.1.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.3.attention.self.query.bias', 'mlmodel.encoder.layer.0.output.dense.weight', 'mlmodel.encoder.layer.1.attention.self.value.bias', 'mlmodel.encoder.layer.5.attention.self.query.bias', 'mlmodel.encoder.layer.5.intermediate.dense.weight', 'mlmodel.encoder.layer.5.attention.self.value.weight', 'mlmodel.encoder.layer.7.attention.self.key.bias', 'mlmodel.encoder.layer.7.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.6.attention.self.query.bias', 'mlmodel.encoder.layer.11.attention.self.key.bias', 'mlmodel.encoder.layer.3.attention.self.value.bias', 'mlmodel.encoder.layer.5.attention.self.value.bias', 'mlmodel.encoder.layer.5.output.LayerNorm.weight', 'mlmodel.encoder.layer.10.attention.self.value.bias', 'mlmodel.encoder.layer.6.attention.output.dense.bias', 'mlmodel.encoder.layer.1.attention.self.query.bias', 'mlmodel.encoder.layer.3.intermediate.dense.weight', 'mlmodel.encoder.layer.8.attention.self.value.bias', 'mlmodel.encoder.layer.8.attention.output.dense.weight', 'mlmodel.embeddings.LayerNorm.weight', 'mlmodel.encoder.layer.0.attention.self.value.bias', 'mlmodel.encoder.layer.6.attention.self.value.weight', 'mlmodel.encoder.layer.11.attention.self.key.weight', 'mlmodel.encoder.layer.2.attention.self.key.bias', 'mlmodel.encoder.layer.4.output.LayerNorm.bias', 'mlmodel.encoder.layer.6.attention.self.key.bias', 'mlmodel.encoder.layer.6.attention.output.dense.weight', 'mlmodel.encoder.layer.10.attention.self.query.bias', 'mlmodel.encoder.layer.0.attention.self.query.weight', 'mlmodel.encoder.layer.10.attention.output.dense.bias', 'mlmodel.encoder.layer.1.attention.self.key.bias', 'mlmodel.encoder.layer.7.attention.output.dense.bias', 'mlmodel.encoder.layer.1.attention.self.key.weight', 'mlmodel.encoder.layer.1.attention.self.query.weight', 'mlmodel.encoder.layer.8.attention.self.query.bias', 'mlmodel.encoder.layer.7.attention.self.query.weight', 'mlmodel.encoder.layer.11.output.dense.bias', 'mlmodel.encoder.layer.7.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.10.attention.self.value.weight', 'mlmodel.encoder.layer.8.output.LayerNorm.bias', 'mlmodel.encoder.layer.11.attention.output.dense.weight', 'mlmodel.encoder.layer.10.attention.self.key.weight', 'mlmodel.encoder.layer.8.attention.self.key.weight', 'mlmodel.encoder.layer.9.attention.output.dense.bias', 'mlmodel.encoder.layer.3.attention.output.dense.bias', 'mlmodel.embeddings.position_ids', 'mlmodel.encoder.layer.1.output.LayerNorm.weight', 'mlmodel.encoder.layer.7.attention.self.key.weight', 'mlmodel.encoder.layer.3.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.6.attention.self.key.weight', 'mlmodel.encoder.layer.5.attention.output.dense.bias', 'mlmodel.encoder.layer.9.attention.self.value.bias', 'mlmodel.encoder.layer.8.output.LayerNorm.weight', 'mlmodel.encoder.layer.6.intermediate.dense.weight', 'mlmodel.encoder.layer.7.attention.self.value.weight', 'mlmodel.encoder.layer.7.attention.self.value.bias', 'mlmodel.encoder.layer.3.output.LayerNorm.weight', 'mlmodel.encoder.layer.0.intermediate.dense.bias', 'mlmodel.encoder.layer.4.intermediate.dense.weight', 'mlmodel.encoder.layer.3.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.5.intermediate.dense.bias', 'mlmodel.encoder.layer.8.output.dense.weight', 'mlmodel.encoder.layer.3.output.LayerNorm.bias', 'mlmodel.encoder.layer.8.attention.self.query.weight', 'mlmodel.encoder.layer.8.attention.self.key.bias', 'mlmodel.encoder.layer.0.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.2.intermediate.dense.weight', 'mlmodel.encoder.layer.6.output.LayerNorm.bias', 'mlmodel.encoder.layer.7.intermediate.dense.bias', 'mlmodel.encoder.layer.1.attention.self.value.weight', 'mlmodel.encoder.layer.7.attention.self.query.bias', 'mlmodel.encoder.layer.9.intermediate.dense.weight', 'mlmodel.encoder.layer.10.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.5.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.11.attention.self.query.bias', 'mlmodel.encoder.layer.7.output.LayerNorm.weight', 'mlmodel.encoder.layer.6.output.dense.weight', 'mlmodel.encoder.layer.11.intermediate.dense.weight', 'mlmodel.encoder.layer.4.output.LayerNorm.weight', 'mlmodel.encoder.layer.5.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.6.output.LayerNorm.weight', 'mlmodel.encoder.layer.11.output.LayerNorm.bias', 'mlmodel.encoder.layer.3.output.dense.weight', 'mlmodel.encoder.layer.6.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.2.attention.self.query.bias', 'mlmodel.encoder.layer.10.attention.output.dense.weight', 'mlmodel.encoder.layer.11.attention.output.LayerNorm.weight', 'mlmodel.embeddings.token_type_embeddings.weight', 'mlmodel.encoder.layer.2.output.dense.weight', 'mlmodel.encoder.layer.2.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.9.intermediate.dense.bias', 'mlmodel.encoder.layer.3.attention.output.dense.weight', 'mlmodel.embeddings.position_embeddings.weight', 'mlmodel.encoder.layer.0.attention.self.query.bias', 'mlmodel.encoder.layer.5.output.LayerNorm.bias', 'mlmodel.encoder.layer.1.output.dense.weight', 'mlmodel.encoder.layer.9.attention.self.value.weight', 'mlmodel.encoder.layer.1.intermediate.dense.weight', 'mlmodel.encoder.layer.10.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.8.intermediate.dense.weight', 'mlmodel.encoder.layer.8.output.dense.bias', 'mlmodel.encoder.layer.7.output.LayerNorm.bias', 'mlmodel.encoder.layer.0.attention.self.key.weight', 'mlmodel.encoder.layer.2.output.LayerNorm.bias', 'mlmodel.encoder.layer.9.output.dense.bias', 'mlmodel.encoder.layer.3.output.dense.bias', 'mlmodel.encoder.layer.1.attention.output.dense.bias', 'mlmodel.encoder.layer.8.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.8.intermediate.dense.bias', 'mlmodel.encoder.layer.6.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.5.attention.self.query.weight', 'mlmodel.encoder.layer.3.attention.self.query.weight', 'mlmodel.encoder.layer.8.attention.output.dense.bias', 'mlmodel.encoder.layer.2.attention.self.key.weight', 'mlmodel.encoder.layer.4.attention.self.key.bias', 'mlmodel.encoder.layer.4.intermediate.dense.bias', 'mlmodel.encoder.layer.5.attention.self.key.bias', 'mlmodel.encoder.layer.4.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.4.attention.self.key.weight', 'mlmodel.encoder.layer.1.output.dense.bias', 'mlmodel.encoder.layer.8.attention.self.value.weight', 'mlmodel.encoder.layer.1.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.4.attention.output.dense.bias', 'mlmodel.encoder.layer.10.output.dense.bias', 'mlmodel.encoder.layer.4.attention.self.query.weight', 'mlmodel.encoder.layer.4.attention.self.value.bias', 'mlmodel.encoder.layer.9.attention.output.LayerNorm.weight', 'mlmodel.encoder.layer.0.output.LayerNorm.weight', 'mlmodel.encoder.layer.1.output.LayerNorm.bias', 'mlmodel.encoder.layer.4.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.5.attention.output.dense.weight', 'mlmodel.encoder.layer.2.attention.output.dense.bias', 'mlmodel.encoder.layer.5.output.dense.bias', 'mlmodel.encoder.layer.2.attention.self.value.weight', 'mlmodel.encoder.layer.0.intermediate.dense.weight', 'mlmodel.encoder.layer.9.output.LayerNorm.bias', 'mlmodel.encoder.layer.9.output.dense.weight', 'mlmodel.encoder.layer.11.attention.self.value.bias', 'mlmodel.encoder.layer.11.intermediate.dense.bias', 'mlmodel.encoder.layer.9.output.LayerNorm.weight', 'mlmodel.encoder.layer.11.attention.self.query.weight', 'mlmodel.encoder.layer.1.attention.output.dense.weight', 'mlmodel.encoder.layer.0.output.LayerNorm.bias', 'mlmodel.encoder.layer.3.attention.self.key.weight', 'mlmodel.encoder.layer.10.output.LayerNorm.bias', 'mlmodel.encoder.layer.0.attention.self.value.weight', 'mlmodel.encoder.layer.9.attention.self.key.weight', 'mlmodel.encoder.layer.11.attention.output.LayerNorm.bias', 'mlmodel.encoder.layer.2.output.LayerNorm.weight', 'classifier.3.weight', 'mlmodel.encoder.layer.5.attention.self.key.weight', 'mlmodel.encoder.layer.3.intermediate.dense.bias', 'classifier.3.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./out/checkpoints/roberta-probing+semcor/checkpoint-185900 and are newly initialized: ['encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'pooler.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing SynsetClassificationModel.\n",
      "\n",
      "All the weights of SynsetClassificationModel were initialized from the model checkpoint at ./out/checkpoints/roberta-probing+semcor/checkpoint-185900.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use SynsetClassificationModel for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# Create the LIT widget with the model and dataset to analyze.\n",
    "from lit_nlp import notebook\n",
    "tr = SemCorDataSet.unpickle(\"dataset/roberta+senseval2.pickle\")\n",
    "lm = LIT_Model('./out/checkpoints/roberta-probing+semcor/checkpoint-185900', tr)\n",
    "lit_models = {'wsd': lm}\n",
    "#datasets = {'sst_dev': glue.SST2Data('validation')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_datasets = {'wsd': LIT_Dataset('dataset/roberta+senseval2.pickle', lm.trainer.tokenizer)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9GSfs1waBdLd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <style>div.output_scroll { height: 1610px; }</style>\n",
       "      <iframe id='lit-frame-1c80317fa3b1799d' width='100%' height='1600' frameborder='0'>\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"lit-frame-1c80317fa3b1799d\");\n",
       "          const urlStr = \"/\" + '?'\n",
       "          const url = new URL(urlStr, window.location);\n",
       "          const port = 18888;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2022 22:49:40] \"GET /? HTTP/1.1\" 200 1406\n",
      "127.0.0.1 - - [29/Mar/2022 22:49:40] \"GET /main.js HTTP/1.1\" 200 1809942\n",
      "127.0.0.1 - - [29/Mar/2022 22:49:40] \"POST /get_info? HTTP/1.1\" 200 42940\n",
      "127.0.0.1 - - [29/Mar/2022 22:49:40] \"GET /static/favicon.png HTTP/1.1\" 200 13257\n",
      "127.0.0.1 - - [29/Mar/2022 22:49:40] \"POST /get_dataset?dataset_name=wsd HTTP/1.1\" 200 433457\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:10] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 1194695655\n",
      "/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py:364: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  pred_spec.vocab.index(label) if label in pred_spec.vocab else -1\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:11] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:11] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:41] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 1194695655\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:41] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=RegressionScore HTTP/1.1\" 200 968\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:41] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=Scalar HTTP/1.1\" 200 968\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2022 22:50:41] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:41] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936852\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:41] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936852\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:41] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:41] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936881\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:42] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936881\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:42] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:42] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936810\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:42] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936810\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2022 22:50:42] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:42] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936694\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936694\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936810\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936810\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"GET /static/potato.svg HTTP/1.1\" 200 3717\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936707\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936707\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936707\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936707\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:43] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936881\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:44] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936881\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:44] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:44] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936707\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:44] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936707\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2022 22:50:54] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:55] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936881\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:55] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936881\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:57] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:57] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936707\n",
      "127.0.0.1 - - [29/Mar/2022 22:50:57] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936707\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n",
      "127.0.0.1 - - [29/Mar/2022 22:51:54] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:51:54] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936604\n",
      "127.0.0.1 - - [29/Mar/2022 22:51:54] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936604\n",
      "ERROR:absl:Uncaught error: operands could not be broadcast together with shapes (82,2584) (1182,)  \n",
      "\n",
      " Traceback (most recent call last):\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 191, in __call__\n",
      "    return self._ServeCustomHandler(request, clean_path, environ)(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/lib/wsgi_app.py\", line 176, in _ServeCustomHandler\n",
      "    return self._handlers[clean_path](self, request, environ)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 385, in _handler\n",
      "    outputs = fn(data, **kw)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/app.py\", line 307, in _get_interpretations\n",
      "    return interpreter.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/api/components.py\", line 112, in run_with_metadata\n",
      "    ret[name] = component.run_with_metadata(indexed_inputs, model, dataset,\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 276, in run_with_metadata\n",
      "    return self._metrics.run_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 203, in run_with_metadata\n",
      "    metrics = self.compute_with_metadata(\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 142, in compute_with_metadata\n",
      "    return self.compute(labels, preds, label_spec, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 367, in compute\n",
      "    pred_idxs = get_classifications(preds, pred_spec, config)\n",
      "  File \"/home/tkrieger/.cache/pypoetry/virtualenvs/bert-wsd-uula_XMy-py3.8/lib/python3.8/site-packages/lit_nlp/components/metrics.py\", line 106, in get_classifications\n",
      "    pred_idx = np.argmax(np.log(p) + logit_mask)\n",
      "ValueError: operands could not be broadcast together with shapes (82,2584) (1182,) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2022 22:52:10] \"POST /get_interpretations?model=wsd&dataset_name=wsd&interpreter=metrics HTTP/1.1\" 500 2357\n",
      "127.0.0.1 - - [29/Mar/2022 22:52:10] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936573\n",
      "127.0.0.1 - - [29/Mar/2022 22:52:10] \"POST /get_preds?model=wsd&dataset_name=wsd&requested_types=MulticlassPreds HTTP/1.1\" 200 4936573\n"
     ]
    }
   ],
   "source": [
    "# Render the widget\n",
    "widget = notebook.LitWidget(lit_models, lit_datasets, height=1600, width=900)\n",
    "widget.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds, _ = load_dataset('dataset/semeval2007-roberta.pickle')\n",
    "#ds.token_level[ds.token_level[\"sense-key-idx1\"] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = SemCorDataSet.unpickle(\"dataset/semcor4roberta.pickle\")\n",
    "tr.all_sense_keys[\"sense-key1\"].unique().shape\n",
    "#sens2, _ = load_dataset('dataset/senseval2-roberta.pickle')\n",
    "#sens3, _ = load_dataset('dataset/senseval3-roberta.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval2007 = SemCorDataSet.unpickle('dataset/semeval2007-roberta.pickle')\n",
    "print(semeval2007.all_sense_keys.shape)\n",
    "pd.merge(tr.all_sense_keys, semeval2007.all_sense_keys, on=\"sense-key1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval2013 = SemCorDataSet.unpickle('dataset/semeval2013-roberta.pickle')\n",
    "print(semeval2013.all_sense_keys.shape)\n",
    "pd.merge(tr.all_sense_keys, semeval2013.all_sense_keys, on=\"sense-key1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval2015 = SemCorDataSet.unpickle('dataset/semeval2015-roberta.pickle')\n",
    "print(semeval2015.all_sense_keys.shape)\n",
    "pd.merge(tr.all_sense_keys, semeval2015.all_sense_keys, on=\"sense-key1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senseval2 = SemCorDataSet.unpickle('dataset/senseval2-roberta.pickle')\n",
    "print(senseval2.all_sense_keys.shape)\n",
    "pd.merge(tr.all_sense_keys, senseval2.all_sense_keys, on=\"sense-key1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senseval3 = SemCorDataSet.unpickle('dataset/senseval3-roberta.pickle')\n",
    "print(senseval3.all_sense_keys.shape)\n",
    "pd.merge(tr.all_sense_keys, senseval3.all_sense_keys, on=\"sense-key1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LIT in Notebooks",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}